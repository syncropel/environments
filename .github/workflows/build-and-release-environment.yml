# ==============================================================================
#  Syncropel Environments CI/CD: Build and Release Single Environment
# ==============================================================================
#
#  Trigger:      Pushing a namespaced Git tag (e.g., 'python-datascience/v1.0.1')
#  Action:       1. Parses the environment name and version from the tag.
#                2. Validates that a corresponding recipe file exists.
#                3. Builds the environment in an isolated Nix shell.
#                4. Packages the environment into a version-agnostic, hash-named tarball.
#                5. Creates a new GitHub Release for that specific tag.
#                6. Uploads the tarball as the sole release artifact.
#
#  This workflow is ATOMIC. It does not modify any central files like the registry.
#
# ==============================================================================

name: Build and Release Single Environment

on:
  push:
    tags:
      - "*/*" # Trigger on any tag with a forward slash, e.g., 'name/v1.2.3'

jobs:
  build-and-release:
    name: Build, Package, and Release Environment
    runs-on: ubuntu-latest
    permissions:
      # Required for the softprops/action-gh-release action to create a GitHub Release.
      contents: write

    steps:
      - name: Checkout Repository Code
        uses: actions/checkout@v4

      - name: Install CI/CD Tooling (Nix, uv, yq)
        uses: cachix/install-nix-action@v27
        with:
          nix_path: nixpkgs=channel:nixos-23.11
      - run: |
          # Install uv, the fast Python package installer from Astral.
          curl -LsSf https://astral.sh/uv/install.sh | sh
          source "$HOME/.cargo/env"

          # Install yq, a lightweight and portable command-line YAML processor.
          sudo wget https://github.com/mikefarah/yq/releases/latest/download/yq_linux_amd64 -O /usr/bin/yq && sudo chmod +x /usr/bin/yq

      - name: Parse Environment Name and Version from Tag
        id: vars
        run: |
          # This step uses robust shell parameter expansion to parse the Git tag.
          # Example tag: python-datascience/v1.0.1
          TAG="${{ github.ref_name }}"

          # ENV_NAME becomes "python-datascience"
          ENV_NAME="${TAG%/*}"

          # ENV_VERSION becomes "1.0.1"
          ENV_VERSION_TAG="${TAG#*/}"
          ENV_VERSION="${ENV_VERSION_TAG#v}"

          echo "Parsed Environment Name: ${ENV_NAME}"
          echo "Parsed Environment Version: ${ENV_VERSION}"

          # Pass these variables to subsequent steps via GitHub Actions outputs.
          echo "env_name=${ENV_NAME}" >> $GITHUB_OUTPUT
          echo "env_version=${ENV_VERSION}" >> $GITHUB_OUTPUT

      - name: Build Specific Environment
        id: build
        run: |
          set -e # Exit immediately if any command fails
          mkdir -p ./artifacts

          # Construct the expected path to the recipe file based on the parsed tag.
          RECIPE_FILE="recipes/${{ steps.vars.outputs.env_name }}/${{ steps.vars.outputs.env_version }}/recipe.yml"

          # --- Critical Validation Step ---
          # Fail fast if a tag was pushed but the corresponding recipe file doesn't exist.
          if [ ! -f "${RECIPE_FILE}" ]; then
            echo "::error::Recipe file not found for tag '${{ github.ref_name }}'. Expected to find it at '${RECIPE_FILE}'."
            exit 1
          fi

          echo "--- Processing Recipe: ${RECIPE_FILE} ---"

          # Generate a content hash of the recipe file. The artifact name is based on this hash.
          # This ensures that identical environments (even with different versions) are not rebuilt/re-uploaded.
          RECIPE_HASH=$(sha256sum ${RECIPE_FILE} | cut -d' ' -f1 | head -c 16)
          ARTIFACT_NAME="env-${RECIPE_HASH}.tar.gz"
          echo "artifact_name=${ARTIFACT_NAME}" >> $GITHUB_OUTPUT
          echo "  - Recipe Hash: ${RECIPE_HASH}"
          echo "  - Artifact Name: ${ARTIFACT_NAME}"

          # Extract system and Python packages from the recipe file using yq.
          SYS_PACKAGES=$(yq e '.tools.system.packages | join(" ")' ${RECIPE_FILE})
          PY_PACKAGES_REQ_FORMAT=$(yq e '.tools.python.packages | .[]' ${RECIPE_FILE})

          # Create a temporary directory for the environment build to ensure a clean state.
          TEMP_ENV_DIR=$(mktemp -d)
          echo "  - Building environment in ${TEMP_ENV_DIR}"

          # --- The Core Build Command ---
          # 1. `nix-shell -p ...`: Starts a temporary shell with all system dependencies available.
          # 2. `--run "..."`: Executes the command string inside that shell.
          # 3. We find the full path to the python executable provided by Nix.
          # 4. We use that full path to create a standard Python virtual environment.
          # 5. We pipe the requirements list directly into uv's stdin for fast installation.
          nix-shell -p ${SYS_PACKAGES} --run "
            PYTHON_EXEC=\$(command -v python3.12) && \
            if [ -z \"\$PYTHON_EXEC\" ]; then echo '::error::python3.12 not found in Nix shell'; exit 1; fi && \
            \$PYTHON_EXEC -m venv ${TEMP_ENV_DIR}/env && \
            echo '${PY_PACKAGES_REQ_FORMAT}' | ${TEMP_ENV_DIR}/env/bin/uv pip install --no-cache-dir -r -
          "

          echo "  - Creating tarball artifact..."
          # The -C flag changes directory before archiving, ensuring clean paths inside the tarball.
          tar -czf ./artifacts/${ARTIFACT_NAME} -C ${TEMP_ENV_DIR} env

      - name: Create GitHub Release and Upload Artifact
        uses: softprops/action-gh-release@v2
        with:
          # Use the full, namespaced Git tag for the release name.
          tag_name: ${{ github.ref_name }}
          # Upload the single, specific artifact built in the previous step.
          files: ./artifacts/${{ steps.build.outputs.artifact_name }}
          # Automatically generate release notes from commit messages.
          generate_release_notes: true
